"""
éå»ãƒ¡ãƒ¢ã¨ã®æ¯”è¼ƒåˆ†ææ©Ÿèƒ½
"""
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta

import google.generativeai as genai

from src.storage.obsidian_manager import ObsidianManager


logger = logging.getLogger(__name__)


class ComparisonAnalyzer:
    """éå»ãƒ¡ãƒ¢ã¨ã®æ¯”è¼ƒåˆ†æ"""

    COMPARISON_PROMPT = """ä»Šå›ã®ãƒ¡ãƒ¢ã¨éå»ã®ãƒ¡ãƒ¢ã‚’æ¯”è¼ƒåˆ†æã—ã¦ãã ã•ã„ã€‚

ã€ä»Šå›ã®ãƒ¡ãƒ¢ã€‘
{current_text}

ã€éå»ã®ãƒ¡ãƒ¢ã€‘
{past_memos}

ä»¥ä¸‹ã®è¦³ç‚¹ã§åˆ†æã—ã¦ãã ã•ã„:
1. **å…±é€šç‚¹**: ä½•ãŒä¸€è²«ã—ã¦ã„ã‚‹ã‹ï¼ˆæŠ€è¡“ã€æ„Ÿè¦šã€ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
2. **å¤‰åŒ–**: ä½•ãŒæ”¹å–„/å¤‰åŒ–ã—ãŸã‹ï¼ˆãƒã‚¸ãƒ†ã‚£ãƒ–ãªå¤‰åŒ–ã€ãƒã‚¬ãƒ†ã‚£ãƒ–ãªå¤‰åŒ–ï¼‰
3. **ãƒ‘ã‚¿ãƒ¼ãƒ³**: ç¹°ã‚Šè¿”ã—å‡ºã¦ãã‚‹ãƒ†ãƒ¼ãƒã‚„å‚¾å‘
4. **ææ¡ˆ**: æ¬¡ã«æ„è­˜ã™ã¹ãã“ã¨ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ°—ã¥ãã‚’ä¿ƒã™è³ªå•å½¢å¼ã§ï¼‰

åˆ†æçµæœã‚’ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„:

## ğŸ“Š éå»ã¨ã®æ¯”è¼ƒ

### å…±é€šç‚¹
[å…±é€šã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚„ä¸€è²«ã—ã¦ã„ã‚‹è¦ç´ ]

### å¤‰åŒ–
[æ”¹å–„ç‚¹ã‚„å¤‰åŒ–ã—ãŸãƒã‚¤ãƒ³ãƒˆ]

### ç¹°ã‚Šè¿”ã—ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
[ç¹°ã‚Šè¿”ã—å‡ºã¦ãã‚‹ãƒ†ãƒ¼ãƒ]

### ğŸ’¡ æ¬¡ã«æ„è­˜ã™ã‚‹ã“ã¨
[è³ªå•å½¢å¼ã§ã®ææ¡ˆ]

é‡è¦: åˆ†æçµæœã®ã¿ã‚’å‡ºåŠ›ã—ã€å‰ç½®ãã‚„èª¬æ˜ã¯ä¸è¦ã§ã™ã€‚
"""

    KEYWORD_EXTRACTION_PROMPT = """ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’3-5å€‹æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

ãƒ†ã‚­ã‚¹ãƒˆ:
{text}

æŠ½å‡ºåŸºæº–:
- æŠ€è¡“åï¼ˆã‚µãƒ¼ãƒ–ã€ãƒ•ã‚©ã‚¢ãƒãƒ³ãƒ‰ã€ãƒãƒƒã‚¯ãƒãƒ³ãƒ‰ãªã©ï¼‰
- èº«ä½“éƒ¨ä½ã‚„æ„Ÿè¦šã«é–¢ã™ã‚‹è¨€è‘‰
- ç·´ç¿’å†…å®¹ã‚„èª²é¡Œã‚’è¡¨ã™è¨€è‘‰

JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„:
{{
  "keywords": ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2", ...]
}}

é‡è¦: JSONä»¥å¤–ã®ãƒ†ã‚­ã‚¹ãƒˆã¯å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„ã€‚
"""

    def __init__(
        self,
        model: genai.GenerativeModel,
        obsidian_manager: ObsidianManager
    ):
        """
        Initialize ComparisonAnalyzer.

        Args:
            model: Gemini GenerativeModel instance
            obsidian_manager: ObsidianManager instance
        """
        self.model = model
        self.obsidian_manager = obsidian_manager

    async def extract_keywords(self, text: str) -> List[str]:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º

        Args:
            text: ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆ
        """
        import json

        prompt = self.KEYWORD_EXTRACTION_PROMPT.format(text=text)

        logger.info("Extracting keywords from text")

        try:
            response = self.model.generate_content(
                prompt,
                generation_config=genai.GenerationConfig(
                    response_mime_type="application/json"
                )
            )

            data = json.loads(response.text)
            keywords = data.get("keywords", [])

            logger.info(f"Extracted keywords: {keywords}")
            return keywords

        except Exception as e:
            logger.error(f"Failed to extract keywords: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç°¡å˜ãªå˜èªåˆ†å‰²
            words = text.split()
            return words[:3] if len(words) >= 3 else words

    async def search_similar_memos(
        self,
        text: str,
        scene_type: Optional[str] = None,
        limit: int = 5,
        exclude_recent_days: int = 0
    ) -> List[Dict[str, Any]]:
        """
        é¡ä¼¼ã™ã‚‹ãƒ¡ãƒ¢ã‚’æ¤œç´¢

        Args:
            text: æ¤œç´¢å¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ
            scene_type: ã‚·ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—ï¼ˆNoneã®å ´åˆã¯å…¨ã‚·ãƒ¼ãƒ³ï¼‰
            limit: å–å¾—ã™ã‚‹æœ€å¤§ä»¶æ•°
            exclude_recent_days: ç›´è¿‘Næ—¥é–“ã‚’é™¤å¤–ï¼ˆ0ã®å ´åˆã¯é™¤å¤–ãªã—ï¼‰

        Returns:
            é¡ä¼¼ãƒ¡ãƒ¢ã®ãƒªã‚¹ãƒˆ
        """
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        keywords = await self.extract_keywords(text)

        if not keywords:
            logger.warning("No keywords extracted, using all memos")
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒãªã„å ´åˆã¯æœ€æ–°ã®ãƒ¡ãƒ¢ã‚’å–å¾—
            return await self.obsidian_manager.get_memos_in_range(
                start_date=(datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d"),
                end_date=datetime.now().strftime("%Y-%m-%d"),
                scene=scene_type,
                limit=limit
            )

        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢
        similar_memos = []
        for keyword in keywords:
            memos = await self.obsidian_manager.search_by_keyword(
                keyword=keyword,
                scene=scene_type,
                limit=limit * 2  # å¤šã‚ã«å–å¾—ã—ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            )
            similar_memos.extend(memos)

        # é‡è¤‡ã‚’é™¤å»ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã§ãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ–ï¼‰
        unique_memos = {}
        for memo in similar_memos:
            filepath = memo.get('filepath', '')
            if filepath and filepath not in unique_memos:
                unique_memos[filepath] = memo

        # æ—¥ä»˜ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆç›´è¿‘Næ—¥ã‚’é™¤å¤–ï¼‰
        if exclude_recent_days > 0:
            cutoff_date = datetime.now() - timedelta(days=exclude_recent_days)
            cutoff_str = cutoff_date.strftime("%Y-%m-%d")

            filtered_memos = [
                memo for memo in unique_memos.values()
                if memo.get('date', '') < cutoff_str
            ]
        else:
            filtered_memos = list(unique_memos.values())

        # æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
        filtered_memos.sort(
            key=lambda m: m.get('date', ''), reverse=True
        )

        # ä»¶æ•°åˆ¶é™
        result = filtered_memos[:limit]

        logger.info(f"Found {len(result)} similar memos (keywords: {keywords})")
        return result

    async def compare_with_past(
        self,
        current_text: str,
        scene_type: Optional[str] = None,
        limit: int = 3
    ) -> str:
        """
        éå»ã®ãƒ¡ãƒ¢ã¨æ¯”è¼ƒåˆ†æ

        Args:
            current_text: ä»Šå›ã®ãƒ¡ãƒ¢ãƒ†ã‚­ã‚¹ãƒˆ
            scene_type: ã‚·ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—
            limit: æ¯”è¼ƒã™ã‚‹éå»ãƒ¡ãƒ¢ã®æœ€å¤§ä»¶æ•°

        Returns:
            æ¯”è¼ƒåˆ†æçµæœï¼ˆMarkdownå½¢å¼ï¼‰
        """
        # é¡ä¼¼ãƒ¡ãƒ¢ã‚’æ¤œç´¢
        similar_memos = await self.search_similar_memos(
            text=current_text,
            scene_type=scene_type,
            limit=limit,
            exclude_recent_days=3  # ç›´è¿‘3æ—¥ã¯é™¤å¤–
        )

        if len(similar_memos) == 0:
            logger.info("No similar memos found")
            return "éå»ã«é¡ä¼¼ã™ã‚‹ãƒ¡ãƒ¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\nã‚‚ã£ã¨ç·´ç¿’ã‚’è¨˜éŒ²ã—ã¦ã¿ã¦ãã ã•ã„ã€‚"

        # éå»ãƒ¡ãƒ¢ã‚’æ•´å½¢
        past_memos_text = ""
        for i, memo in enumerate(similar_memos, 1):
            date = memo.get('date', 'æ—¥ä»˜ä¸æ˜')
            scene = memo.get('scene', 'unknown')
            body = memo.get('raw_text', '') or memo.get('body', '')

            # é•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šæ¨ã¦
            if len(body) > 300:
                body = body[:300] + "..."

            past_memos_text += f"""{i}. {date} ({scene})
{body}

"""

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        prompt = self.COMPARISON_PROMPT.format(
            current_text=current_text,
            past_memos=past_memos_text
        )

        logger.info(f"Comparing with {len(similar_memos)} past memos")

        try:
            # Geminiã§æ¯”è¼ƒåˆ†æ
            response = self.model.generate_content(prompt)
            analysis = response.text.strip()

            logger.info("Comparison analysis completed")
            return analysis

        except Exception as e:
            logger.error(f"Failed to generate comparison analysis: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return f"""## ğŸ“Š éå»ã¨ã®æ¯”è¼ƒ

éå»ã« {len(similar_memos)} ä»¶ã®é¡ä¼¼ã™ã‚‹ãƒ¡ãƒ¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:

{past_memos_text}

**ã‚¨ãƒ©ãƒ¼**: åˆ†æã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ‰‹å‹•ã§æ¯”è¼ƒã—ã¦ã¿ã¦ãã ã•ã„ã€‚
"""
